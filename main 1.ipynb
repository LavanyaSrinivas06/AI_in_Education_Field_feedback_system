{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load your custom stopwords\n",
    "# Assuming your stopwords are in a file called 'stopwords.txt'\n",
    "with open('stop_words_list.py', 'r') as file:\n",
    "    custom_stopwords = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load your dataset Assuming your dataset has two columns:  (feedback) and  (label)\n",
    "df = pd.read_csv('text_feedback_dataset.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            feedback     label\n",
      "0  I really enjoyed the lecture, it was very info...  Positive\n",
      "1  The concepts were explained clearly, I learned...  Positive\n",
      "2  The course is good, but some parts were a bit ...   Neutral\n",
      "3  I'm not sure if I understood the topic complet...   Neutral\n",
      "4  The teacher was a bit too fast, I had trouble ...  Negative\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Preprocess the data\n",
    "# Check the dataset structure\n",
    "print(df.head())\n",
    "\n",
    "# Ensure there are no missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "#X = df['feedback']  # Feedback text\n",
    "#y = df['label']  # Sentiment labels (e.g., Positive, Negative, Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clean the feedback text (removing special characters, numbers, etc.)\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df['cleaned_feedback'] = df['feedback'].apply(clean_text)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['cleaned_feedback']  # Cleaned feedback text\n",
    "y = df['label']  # Sentiment labels (e.g., Positive, Negative, Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "label\n",
      "Positive    508\n",
      "Neutral     506\n",
      "Negative    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            feedback     label  \\\n",
      "0  I really enjoyed the lecture, it was very info...  Positive   \n",
      "1  The concepts were explained clearly, I learned...  Positive   \n",
      "2  The course is good, but some parts were a bit ...   Neutral   \n",
      "3  I'm not sure if I understood the topic complet...   Neutral   \n",
      "4  The teacher was a bit too fast, I had trouble ...  Negative   \n",
      "\n",
      "                                    cleaned_feedback  \n",
      "0  i really enjoyed the lecture it was very infor...  \n",
      "1  the concepts were explained clearly i learned ...  \n",
      "2  the course is good but some parts were a bit c...  \n",
      "3   im not sure if i understood the topic completely  \n",
      "4  the teacher was a bit too fast i had trouble k...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Convert text data into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=custom_stopwords)\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features Shape: (1513, 867)\n",
      "First Sample's TF-IDF Features:\n",
      "  (0, 385)\t0.3601817923566046\n",
      "  (0, 816)\t0.32087586546517\n",
      "  (0, 824)\t0.1898226655871949\n",
      "  (0, 414)\t0.2443390664275278\n",
      "  (0, 438)\t0.43155041983982456\n",
      "  (0, 737)\t0.15220370568107916\n",
      "  (0, 227)\t0.441662339342848\n",
      "  (0, 607)\t0.5168231581331081\n"
     ]
    }
   ],
   "source": [
    "# Check TF-IDF features\n",
    "print(\"\\nTF-IDF Features Shape:\", X_tfidf.shape)\n",
    "print(\"First Sample's TF-IDF Features:\")\n",
    "print(X_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Hyperparameter tuning using GridSearchCV\n",
    "penalty=['l1', 'l2', 'elasticnet']\n",
    "c_values=[100,10,1.0,0.1,0.01]\n",
    "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "param_grid = dict(penalty=penalty, C=c_values, solver=solver)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv=StratifiedKFold()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the model\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.81      0.84       113\n",
      "     Neutral       0.82      0.78      0.80        92\n",
      "    Positive       0.85      0.95      0.90        98\n",
      "\n",
      "    accuracy                           0.85       303\n",
      "   macro avg       0.85      0.85      0.85       303\n",
      "weighted avg       0.85      0.85      0.85       303\n",
      "\n",
      "Accuracy: 0.8481848184818482\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Use the trained model to predict sentiment for new feedback\n",
    "def predict_sentiment(feedback, vectorizer, model):\n",
    "    # Clean the feedback text (same preprocessing as before)\n",
    "    feedback_cleaned = clean_text(feedback)\n",
    "    \n",
    "    # Transform the cleaned feedback into TF-IDF features\n",
    "    feedback_tfidf = vectorizer.transform([feedback_cleaned])\n",
    "    \n",
    "    # Predict the sentiment\n",
    "    sentiment = model.predict(feedback_tfidf)[0]\n",
    "    print(\"Predicted Sentiment:\",sentiment)\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deepface\n",
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "def capture_emotion():\n",
    "    \"\"\"\n",
    "    Captures an image from the webcam when the space key is pressed,\n",
    "    detects the face, analyzes the emotion, and prints the detected emotion.\n",
    "    \"\"\"\n",
    "    # Load face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Start capturing video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Press 'SPACE' to capture an image and detect emotion. Press 'q' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw rectangle around detected face\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Press SPACE to Capture', frame)\n",
    "\n",
    "        # Capture image on 'SPACE' key press\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):  # Space key pressed\n",
    "            if len(faces) == 0:\n",
    "                print(\"No face detected. Try again.\")\n",
    "            else:\n",
    "                print(\"Capturing image and analyzing emotion...\")\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face_roi = frame[y:y + h, x:x + w]  # Extract face ROI\n",
    "\n",
    "                    try:\n",
    "                        # Perform emotion analysis\n",
    "                        result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "                        emotion = result[0]['dominant_emotion']\n",
    "                        print(f\"Detected Emotion: {emotion}\")\n",
    "\n",
    "                        # Display detected emotion on image\n",
    "                        cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "                        cv2.imshow(\"Captured Emotion\", frame)\n",
    "                        cv2.waitKey(2000)  # Show detected emotion for 2 seconds\n",
    "\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        return emotion  # Return detected emotion\n",
    "                    except Exception as e:\n",
    "                        print(\"Error analyzing emotion:\", e)\n",
    "\n",
    "        # Exit on 'q' key press\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return None  # Return None if no emotion detected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n",
      "Press 'SPACE' to capture an image and detect emotion. Press 'q' to exit.\n",
      "Capturing image and analyzing emotion...\n",
      "Detected Emotion: neutral\n",
      "The feedback is not genuine\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_feedback = input(\"Enter feedback text: \")\n",
    "sentiment = predict_sentiment(input_feedback, vectorizer, best_model)\n",
    "emotion = capture_emotion()\n",
    "if sentiment == 'Positive' and emotion == 'happy':\n",
    "    print(\"The feedback is genuine\")\n",
    "elif sentiment == 'Negative' and emotion == 'angry':\n",
    "    print(\"The feedback is genuine\")\n",
    "elif sentiment == 'Neutral' and emotion == 'neutral':\n",
    "    print(\"The feedback is genuine\")\n",
    "else:\n",
    "    print(\"The feedback is not genuine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
