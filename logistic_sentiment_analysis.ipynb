{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (3.9.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lavan\\onedrive\\desktop\\college- srh\\course\\2nd sem\\ai_in_education_field_feedback_system\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources (if not already downloaded)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load your custom stopwords\n",
    "# Assuming your stopwords are in a file called 'stopwords.txt'\n",
    "with open('stop_words_list.py', 'r') as file:\n",
    "    custom_stopwords = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Load your dataset Assuming your dataset has two columns:  (feedback) and  (label)\n",
    "df = pd.read_csv('text_feedback_dataset.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            feedback     label\n",
      "0  I really enjoyed the lecture, it was very info...  Positive\n",
      "1  The concepts were explained clearly, I learned...  Positive\n",
      "2  The course is good, but some parts were a bit ...   Neutral\n",
      "3  I'm not sure if I understood the topic complet...   Neutral\n",
      "4  The teacher was a bit too fast, I had trouble ...  Negative\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Preprocess the data\n",
    "# Check the dataset structure\n",
    "print(df.head())\n",
    "\n",
    "# Ensure there are no missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "#X = df['feedback']  # Feedback text\n",
    "#y = df['label']  # Sentiment labels (e.g., Positive, Negative, Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Clean the feedback text (removing special characters, numbers, etc.)\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "df['cleaned_feedback'] = df['feedback'].apply(clean_text)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['cleaned_feedback']  # Cleaned feedback text\n",
    "y = df['label']  # Sentiment labels (e.g., Positive, Negative, Neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "label\n",
      "Positive    508\n",
      "Neutral     506\n",
      "Negative    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            feedback     label  \\\n",
      "0  I really enjoyed the lecture, it was very info...  Positive   \n",
      "1  The concepts were explained clearly, I learned...  Positive   \n",
      "2  The course is good, but some parts were a bit ...   Neutral   \n",
      "3  I'm not sure if I understood the topic complet...   Neutral   \n",
      "4  The teacher was a bit too fast, I had trouble ...  Negative   \n",
      "\n",
      "                                    cleaned_feedback  \n",
      "0  i really enjoyed the lecture it was very infor...  \n",
      "1  the concepts were explained clearly i learned ...  \n",
      "2  the course is good but some parts were a bit c...  \n",
      "3   im not sure if i understood the topic completely  \n",
      "4  the teacher was a bit too fast i had trouble k...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lavan\\OneDrive\\Desktop\\College- SRH\\Course\\2nd Sem\\AI_in_Education_Field_feedback_system\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['about', 'above', 'after', 'again', 'against', 'all', 'an', 'and', 'answered', 'any', 'as', 'asked', 'assignment', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'class', 'content', 'course', 'covered', 'did', 'discussion', 'do', 'does', 'doing', 'down', 'during', 'each', 'explained', 'few', 'for', 'from', 'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'if', 'in', 'instructor', 'into', 'is', 'it', 'its', 'itself', 'just', 'learning', 'lecture', 'listening', 'material', 'me', 'more', 'most', 'my', 'myself', 'noted', 'notes', 'now', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'presentation', 'professor', 'questions', 'reading', 'same', 'session', 'set', 'she', 'should', 'slide', 'so', 'some', 'stop_words_list', 'studying', 'such', 'talked', 'teacher', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'topic', 'under', 'understood', 'until', 'up', 'very', 'video', 'was', 'watching', 'we', 'went', 'were', 'when', 'where', 'while', 'why', 'will', 'with', 'you', 'your', 'yours', 'yourself', 'yourselves'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Convert text data into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=custom_stopwords)\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Features Shape: (1513, 867)\n",
      "First Sample's TF-IDF Features:\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 8 stored elements and shape (1, 867)>\n",
      "  Coords\tValues\n",
      "  (0, 607)\t0.5168231581331081\n",
      "  (0, 227)\t0.44166233934284804\n",
      "  (0, 737)\t0.1522037056810792\n",
      "  (0, 438)\t0.4315504198398246\n",
      "  (0, 414)\t0.24433906642752787\n",
      "  (0, 824)\t0.18982266558719493\n",
      "  (0, 816)\t0.32087586546517005\n",
      "  (0, 385)\t0.36018179235660464\n"
     ]
    }
   ],
   "source": [
    "# Check TF-IDF features\n",
    "print(\"\\nTF-IDF Features Shape:\", X_tfidf.shape)\n",
    "print(\"First Sample's TF-IDF Features:\")\n",
    "print(X_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Solvers to try\n",
    "    'max_iter': [100, 200, 300]  # Iterations for convergence\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model after tuning\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate the model\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'C': 1, 'max_iter': 200, 'solver': 'saga'}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.81      0.84       113\n",
      "     Neutral       0.82      0.78      0.80        92\n",
      "    Positive       0.85      0.95      0.90        98\n",
      "\n",
      "    accuracy                           0.85       303\n",
      "   macro avg       0.85      0.85      0.85       303\n",
      "weighted avg       0.85      0.85      0.85       303\n",
      "\n",
      "Accuracy: 0.8481848184818482\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Use the trained model to predict sentiment for new feedback\n",
    "def predict_sentiment(feedback, vectorizer, model):\n",
    "    # Clean the feedback text (same preprocessing as before)\n",
    "    feedback_cleaned = clean_text(feedback)\n",
    "    \n",
    "    # Transform the cleaned feedback into TF-IDF features\n",
    "    feedback_tfidf = vectorizer.transform([feedback_cleaned])\n",
    "    \n",
    "    # Predict the sentiment\n",
    "    sentiment = model.predict(feedback_tfidf)[0]\n",
    "    \n",
    "    return sentiment\n",
    "\n",
    "# Example usage\n",
    "new_feedback = \"the course was  informative , i learnt from basic\"\n",
    "predicted_sentiment = predict_sentiment(new_feedback, vectorizer, best_model)\n",
    "print(f\"\\nPredicted Sentiment: {predicted_sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
